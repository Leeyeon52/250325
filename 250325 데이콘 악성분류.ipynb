{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 데이터 로드 중...\n",
      "🔍 URL 컬럼명 변경 중...\n",
      "🗑️ 결측값 및 중복 제거 중...\n",
      "📊 TF-IDF 벡터화 중...\n",
      "✂️ 데이터 분할 중...\n",
      "🔍 GridSearchCV 학습 중...\n",
      "GridSearchCV 학습 완료\n",
      "🧪 검증 데이터 평가 중...\n",
      "검증 데이터 정확도: 0.43333333333333335\n",
      "📈 교차 검증 점수 확인 중...\n",
      "교차 검증 정확도: 0.5000 (+/- 0.0456)\n",
      "📝 테스트 데이터 예측 중...\n",
      "📁 제출 파일 생성 중...\n",
      "✅ 제출 파일 생성 완료: submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 파일 경로 설정\n",
    "train_path = \"train.csv\"\n",
    "test_path = \"test.csv\"\n",
    "sample_submission_path = \"sample_submission.csv\"\n",
    "output_path = \"submission.csv\"\n",
    "\n",
    "# 파일 존재 여부 확인\n",
    "def check_file_exists(path):\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"❌ 파일을 찾을 수 없습니다: {path}. 파일을 확인하세요.\")\n",
    "\n",
    "for path in [train_path, test_path, sample_submission_path]:\n",
    "    check_file_exists(path)\n",
    "\n",
    "# 데이터 로드\n",
    "print(\"📂 데이터 로드 중...\")\n",
    "df_train = pd.read_csv(train_path)\n",
    "df_test = pd.read_csv(test_path)\n",
    "df_sample = pd.read_csv(sample_submission_path)\n",
    "\n",
    "# URL 컬럼명 변경 (자동 감지)\n",
    "def rename_url_column(df):\n",
    "    for col in df.columns:\n",
    "        if 'url' in col.lower():\n",
    "            df.rename(columns={col: 'URL'}, inplace=True)\n",
    "            return df\n",
    "    raise KeyError(\"❌ 'URL' 컬럼을 찾을 수 없습니다. 파일을 확인하세요.\")\n",
    "\n",
    "try:\n",
    "    print(\"🔍 URL 컬럼명 변경 중...\")\n",
    "    df_train = rename_url_column(df_train)\n",
    "    df_test = rename_url_column(df_test)\n",
    "except KeyError as e:\n",
    "    print(e)\n",
    "    exit(1)\n",
    "\n",
    "# 결측값 및 중복 제거\n",
    "print(\"🗑️ 결측값 및 중복 제거 중...\")\n",
    "df_train = df_train.dropna().drop_duplicates()\n",
    "df_test = df_test.dropna().drop_duplicates()\n",
    "\n",
    "# 특징(X)와 타겟(y) 분리\n",
    "if 'malicious' not in df_train.columns:\n",
    "    raise KeyError(\"❌ 'malicious' 컬럼이 train.csv에 없습니다. 파일을 확인하세요.\")\n",
    "X_texts = df_train['URL'].astype(str)\n",
    "y = df_train['malicious'].astype(int)\n",
    "\n",
    "# TF-IDF 벡터화\n",
    "print(\"📊 TF-IDF 벡터화 중...\")\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1, 3), stop_words='english')\n",
    "X_tfidf = vectorizer.fit_transform(X_texts)\n",
    "test_tfidf = vectorizer.transform(df_test['URL'].astype(str))\n",
    "\n",
    "# 데이터 분할\n",
    "print(\"✂️ 데이터 분할 중...\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 랜덤 포레스트 모델 학습 및 하이퍼파라미터 튜닝\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# GridSearchCV로 하이퍼파라미터 튜닝\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # 트리의 개수\n",
    "    'max_depth': [10, 20, 50, None],  # 트리의 최대 깊이\n",
    "    'min_samples_split': [2, 5, 10],  # 노드를 분할하기 위한 최소 샘플 수\n",
    "    'min_samples_leaf': [1, 2, 4]  # 리프 노드가 되기 위한 최소 샘플 수\n",
    "}\n",
    "\n",
    "# GridSearchCV 객체 정의 및 학습\n",
    "print(\"🔍 GridSearchCV 학습 중...\")\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"GridSearchCV 학습 완료\")\n",
    "\n",
    "# 최적의 모델 사용\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# 검증 데이터 평가\n",
    "print(\"🧪 검증 데이터 평가 중...\")\n",
    "y_pred_rf = best_rf_model.predict(X_val)\n",
    "print(\"검증 데이터 정확도:\", accuracy_score(y_val, y_pred_rf))\n",
    "\n",
    "# 교차 검증 점수 확인\n",
    "print(\"📈 교차 검증 점수 확인 중...\")\n",
    "cv_scores = cross_val_score(best_rf_model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(f\"교차 검증 정확도: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "print(\"📝 테스트 데이터 예측 중...\")\n",
    "y_test_pred = best_rf_model.predict(test_tfidf)\n",
    "\n",
    "# 제출 파일 컬럼 확인 및 정리\n",
    "if 'id' not in df_sample.columns:\n",
    "    df_sample.insert(0, 'id', range(1, len(df_sample) + 1))\n",
    "if 'malicious' not in df_sample.columns:\n",
    "    df_sample['malicious'] = y_test_pred.astype(int)\n",
    "else:\n",
    "    df_sample['malicious'] = y_test_pred.astype(int)\n",
    "\n",
    "# 컬럼 순서 조정\n",
    "df_sample = df_sample[['id', 'malicious']]\n",
    "\n",
    "# 제출 파일 생성\n",
    "print(\"📁 제출 파일 생성 중...\")\n",
    "df_sample.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"✅ 제출 파일 생성 완료: {output_path}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
